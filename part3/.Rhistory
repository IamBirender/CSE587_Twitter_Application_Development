for(k in keywords){
filename <- glue('tw-',{k},'.csv')
tempread <- read.csv("filename")
mylength <- mylength + length(tempread)
}
# keywords
# flu vaccine flu&shot h1n1 tamiflu influenza headache lymph sinus
keywords <- c("flu","vaccine","h1n1","tamiflu","influenza","headache","lymph","sinus")
for(k in keywords){
filename <- glue('tw-',{as.character(k)},'.csv')
tempread <- read.csv("filename")
mylength <- mylength + length(tempread)
}
for(k in keywords){
filename <- glue('tw-',{as.character(k)},'.csv')
tempread <- read.csv(filename)
mylength <- mylength + length(tempread)
}
mylength
for(k in keywords){
if(k !== "h1n1"){
filename <- glue('tw-',{as.character(k)},'.csv')
tempread <- read.csv(filename)
mylength <- mylength + length(tempread)
}
}
for(k in keywords){
if(k != "h1n1"){
filename <- glue('tw-',{as.character(k)},'.csv')
tempread <- read.csv(filename)
mylength <- mylength + length(tempread)
}
}
mylength
View(userStates)
count(userStatesFlu, state)
install.packages("tibble")
install.packages("tibble")
install.packages("tibble")
install.packages("tibble")
library(tibble)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
library(ggplot2)
library(maptools)
library(maps)
library(usmap)
library(sp)
library(rgdal)
library(revgeo)
library(sf)
library(tibble)
setup_twitter_oauth(
key_get("twitter_consumer_key", keyring = "mykeyring"),
key_get("twitter_consumer_secret", keyring = "mykeyring"),
key_get("twitter_access_token", keyring = "mykeyring"),
key_get("twitter_access_secret", keyring = "mykeyring")
)
register_google(key_get("GoogleAPI", keyring = "mykeyring"))
library(twitteR)
library(twitteR)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
library(ggplot2)
library(maptools)
library(maps)
library(usmap)
library(sp)
library(rgdal)
library(revgeo)
library(sf)
library(tibble)
setup_twitter_oauth(
key_get("twitter_consumer_key", keyring = "mykeyring"),
key_get("twitter_consumer_secret", keyring = "mykeyring"),
key_get("twitter_access_token", keyring = "mykeyring"),
key_get("twitter_access_secret", keyring = "mykeyring")
)
register_google(key_get("GoogleAPI", keyring = "mykeyring"))
library(twitteR)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(twitteR)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
install.packages("tidyverse")
library(twitteR)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
library(ggplot2)
library(maptools)
library(maps)
library(usmap)
library(sp)
library(rgdal)
library(revgeo)
library(sf)
setup_twitter_oauth(
key_get("twitter_consumer_key", keyring = "mykeyring"),
key_get("twitter_consumer_secret", keyring = "mykeyring"),
key_get("twitter_access_token", keyring = "mykeyring"),
key_get("twitter_access_secret", keyring = "mykeyring")
)
register_google(key_get("GoogleAPI", keyring = "mykeyring"))
# keywords
# flu vaccine flu&shot h1n1 tamiflu influenza headache lymph sinus
keywords <- c("flu","vaccine","h1n1","tamiflu","influenza","headache","lymph","sinus")
stateTweetCount <- count(userStatesFlu, state)
stateTweetCount
typeof(stateTweetCount)
plot_usmap(regions = "states", data = stateTweetCount, values = "n", lines = "red") +
scale_fill_continuous(low = "white", high = "red", name = "Flu Tweets", label = scales::comma)
plot_usmap(regions = "states", data = stateTweetCount, values = "n", lines = "red")
+ scale_fill_continuous(low = "white", high = "red", name = "Flu Tweets", label = scales::comma)
+ theme(legend.position = "right")
plot_usmap(regions = "states", data = stateTweetCount, values = "n", lines = "red")+
scale_fill_continuous(low = "white", high = "red", name = "Flu Tweets", label = scales::comma)+
theme(legend.position = "right")
typeof(keywords)
(getCurRateLimitInfo(c("search")))$remaining
for(k in keywords){
print(typeof(k))
print(k)
print(as.character(k))
}
View(userStatesFlu)
View(geo.users)
View(geocoded.users)
View(geocoded.users.full)
summary(userStatesFlu)
View(userStates)
View(userStatesFlu)
View(usersLatLng)
View(usersLatLng)
View(stateTweetCount)
View(userStatesFlu)
View(stateTweetCount)
View(userStates)
keywords <- c("headache", "lymph", "sinus")
dates <- seq(as.Date("2019-03-03"), as.Date("2019-03-03"), by=1)
library(twitteR)
setup_twitter_oauth(
key_get("twitter_consumer_key", keyring = "mykeyring"),
key_get("twitter_consumer_secret", keyring = "mykeyring"),
key_get("twitter_access_token", keyring = "mykeyring"),
key_get("twitter_access_secret", keyring = "mykeyring")
)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
library(ggplot2)
library(maptools)
library(maps)
library(usmap)
library(sp)
library(rgdal)
library(revgeo)
setup_twitter_oauth(
key_get("twitter_consumer_key", keyring = "mykeyring"),
key_get("twitter_consumer_secret", keyring = "mykeyring"),
key_get("twitter_access_token", keyring = "mykeyring"),
key_get("twitter_access_secret", keyring = "mykeyring")
)
register_google(key_get("GoogleAPI", keyring = "mykeyring"))
keywords <- c("headache", "lymph", "sinus")
getCurRateLimitInfo(c("search"))
# If limit has been reached, sleep until API reset time
if(myRateLimit$remaining < 1){
resetTime <- myRateLimit$reset
nowTime <- with_tz(Sys.time(), tz="UTC")
sleepingTime <- as.numeric(resetTime-nowTime, units="secs")
print(glue('Sleeping for ',{sleepingTime}))
Sys.sleep(as.numeric(resetTime-nowTime, units="secs"))
}
# Check current API rate limit
myRateLimit <- getCurRateLimitInfo(c("search"))
# If limit has been reached, sleep until API reset time
if(myRateLimit$remaining < 1){
resetTime <- myRateLimit$reset
nowTime <- with_tz(Sys.time(), tz="UTC")
sleepingTime <- as.numeric(resetTime-nowTime, units="secs")
print(glue('Sleeping for ',{sleepingTime}))
Sys.sleep(as.numeric(resetTime-nowTime, units="secs"))
}
for(day in as.list(dates)){
for(k in keywords){
# Check current API rate limit
myRateLimit <- getCurRateLimitInfo(c("search"))
# If limit has been reached, sleep until API reset time
if(myRateLimit$remaining < 1){
resetTime <- myRateLimit$reset
nowTime <- with_tz(Sys.time(), tz="UTC")
sleepingTime <- as.numeric(resetTime-nowTime, units="secs")
print(glue('Sleeping for ',{sleepingTime}))
Sys.sleep(as.numeric(resetTime-nowTime, units="secs"))
}
searchWord <- as.character(k)
# Construct filename based on keyword
filename <- glue('tw-',{searchWord},'.csv')
print(glue('Attemping search of ',{searchWord}, ' since ',as.character(day),' until ',as.character(day+1)))
# Searches Twitter API for provided dates given searchWord, then strips any retweets, and converts to DF
dtweets <- twListToDF(strip_retweets(searchTwitter(searchWord, n=900, since=as.character(day), until = as.character(day+1), retryOnRateLimit = 450)))
print(glue('Completed search of ',{searchWord}, ' with ',{nrow(dtweets)},' rows'))
print(glue('Appending to ',{filename}))
if(!file.exists(filename)){
write.csv(dtweets, file=filename)
} else {
existingCSV <- read.csv(file = filename, stringsAsFactors = F)
existingCSV <- select(existingCSV, -c("X"))
newCSV <- rbind(existingCSV, dtweets)
write.csv(newCSV, file=filename)
#write.table(dtweets, file = "tw-sinusrow.csv", sep = ",", col.names = NA, append = T, qmethod = "double")
}
}
}
geoprep.data <- read.csv("tw-flu.csv")
View(geoprep.data)
geoprep.data <- select(geoprep.data, "screenName")
View(geoprep.data)
# Query Twitter API for data frame of user profile information
geoprep.users <- twListToDF(lookupUsers(as.character(geoprep.data$screenName), includeNA = FALSE))
View(geocoded.users)
View(geoprep.users)
# Select only users with a non-empty location listed and only keep columns 'screenName' and 'location'
geoprep.users <- select(subset(geoprep.users, location != ""), screenName, location)
View(geoprep.users)
# Query Google Maps API to geocode user locations
geoprep.users.locgeocoded <- geocode(geoprep.users$location)
View(geoprep.users.locgeocoded)
# Add latitude and longitude columns to geocoded.users
geocoded.users <- dplyr::mutate(geoprep.users.locgeocoded, latitude = geocoded.users$lat)
View(geoprep.users)
View(geoprep.users.locgeocoded)
View(geoprep.users)
# Add latitude and longitude columns to geocoded.users
geocoded.users <- dplyr::mutate(geoprep.users, latitude = geoprep.users.locgeocoded$lat)
View(geocoded.users)
geocoded.users <- dplyr::mutate(geocoded.users, longitude = geoprep.users.locgeocoded$lon)
View(geocoded.users)
write.csv(geocoded.users, file = "geo-users-tw-flu.csv")
# Drop imprecise rows where geocode failed such as locations of "sitting in grass" or "somewhere"
geocoded.users <- drop_na(geocoded.users)
# Drop imprecise rows where geocode returned merely the geographical center of the United States
geocoded.users.nogeneric <- geocoded.users[!(geocoded.users$latitude==37.0902400 & geocoded.users$longitude==-95.7128910),]
detach(rgdal)
detach(revgeo)
View(geocoded.users.nogeneric)
geocoded.users.nogeneric[1,]
geocoded.users.nogeneric[1,3]
googlerevgeo <- revgeocode(c(geocoded.users.nogeneric[1,4], geocoded.users.nogeneric[1,3]), output="all")
View(googlerevgeo)
googlerevgeo <- revgeocode(c(geocoded.users.nogeneric[2,4], geocoded.users.nogeneric[2,3]), output="all")
View(googlerevgeo)
geocoded.users.nogeneric[2,]
geocoded.users.nogeneric[2,4]
View(googlerevgeo)
googlerevgeo <- revgeocode(c(geocoded.users.nogeneric[2,4], geocoded.users.nogeneric[2,3]), output="all")
View(googlerevgeo)
googlerevgeo <- revgeocode(c(geocoded.users.nogeneric[2,4], geocoded.users.nogeneric[2,3]), output="address")
googlerevgeo <- revgeocode(c(geocoded.users.nogeneric[2,4], geocoded.users.nogeneric[2,3]), output="all")
View(googlerevgeo)
install.packages("jsonlite")
install.packages("jsonlite")
library(twitteR)
library(keyring)
library(lubridate)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
library(ggplot2)
library(maptools)
library(maps)
library(usmap)
library(sp)
library(jsonlite)
library("jsonlite")
library(jsonlite)
install.packages(jsonlite)
install.packages('jsonlite')
install.packages('jsonlite')
library(jsonlite)
shiny::runApp('shinyapp')
runApp('shinyapp')
count(state.name)
state.name
count(data.frame(state = state.name))
runApp('shinyapp')
runApp('shinyapp')
runApp('shinyapp')
runApp('shinyapp')
runApp('shinyapp')
runApp('shinyapp')
stateTweetFullList <- NULL
for(k in keywords){
if(is.null(stateTweetFullList)){
stateTweetFullList <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
} else {
uniqueCSV <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
stateTweetFullList <- rbind(stateTweetFullList, uniqueCSV)
}
}
stateTweetUniqueList <- unique(stateTweetFullList, by = "tweetID")
totalTweetsPerState <- count(stateTweetFullList, state)
View(totalTweetsPerState)
View(stateTweetUniqueList)
# Set keywords
# flu vaccine h1n1 tamiflu influenza headache lymph sinus
keywords <- c("flu","vaccine","h1n1","tamiflu","influenza","headache","lymph","sinus")
stateTweetFullList <- NULL
for(k in keywords){
if(is.null(stateTweetFullList)){
stateTweetFullList <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
} else {
uniqueCSV <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
stateTweetFullList <- rbind(stateTweetFullList, uniqueCSV)
}
}
stateTweetUniqueList <- unique(stateTweetFullList, by = "tweetID")
totalTweetsPerState <- count(stateTweetFullList, state)
View(stateTweetUniqueList)
plot_usmap(regions = "states", data = totalTweetsPerState, values = "n", lines = "red")+
scale_fill_continuous(low = "white", high = "red", name = "Flu Tweets", label = scales::comma)+
theme(legend.position = "right")
totalTweetsPerState <- count(stateTweetFullList, state)
plot_usmap(regions = "states", data = totalTweetsPerState, values = "n", lines = "red")+
scale_fill_continuous(low = "white", high = "red", name = "Flu Tweets", label = scales::comma)+
theme(legend.position = "right")
runApp('shinyapp')
runApp('shinyapp')
version
library(ggmap)
library(maps)
heat_data<- read.csv(file = "Data/StateDataforMap_2018-19week8.csv")
heat_data<- read.csv(file = "Data/StateDataforMap_2018-19week8.csv")
# x1
heat_data$Val<- gsub("[^0-9\\.]","", heat_data$ACTIVITY.LEVEL)
heat_val<-as.integer(heat_data$Val)
us <- map_data("state")
gplot <-ggplot()
gplot <- gplot + geom_map(data=us, map=us,aes(x=long, y=lat, map_id=region),fill="#ffffff", color="#ffffff", size=0.5)
gplot <- gplot + geom_map(data=heat_data, map=us, aes(fill=heat_val, map_id=tolower(STATENAME)),color="#000000", size=0.5)
gplot <- gplot + scale_fill_continuous(low='white',high='red', guide='colorbar')
# gplot = gplot + scale_fill_gradient2(low="darkgreen", mid="yellow", high="darkred", midpoint=5, limits=range(heat$level))
gplot <- gplot + ggtitle("2018-19 Influenza Season Week 8 ending Feb 23, 2019")
gplot <- gplot + coord_map("mercator")
gplot <- gplot + theme_void()
gplot
library(maptools)
gplot
library(ggplot2)
gplot
version
runApp('shinyapp')
library(ggmap)
library(maps)
library(maptools)
library(ggplot2)
heat_data<- read.csv(file = "Data/StateDataforMap_2018-19week8.csv")
# x1
heat_data$Val<- gsub("[^0-9\\.]","", heat_data$ACTIVITY.LEVEL)
heat_val<-as.integer(heat_data$Val)
us <- map_data("state")
gplot <-ggplot()
gplot <- gplot + geom_map(data=us, map=us,aes(x=long, y=lat, map_id=region),fill="#ffffff", color="#ffffff", size=0.5)
gplot <- gplot + geom_map(data=heat_data, map=us, aes(fill=heat_val, map_id=tolower(STATENAME)),color="#000000", size=0.5)
gplot <- gplot + scale_fill_continuous(low='white',high='red', guide='colorbar')
# gplot = gplot + scale_fill_gradient2(low="darkgreen", mid="yellow", high="darkred", midpoint=5, limits=range(heat$level))
gplot <- gplot + ggtitle("2018-19 Influenza Season Week 8 ending Feb 23, 2019")
gplot <- gplot + coord_map("mercator")
gplot <- gplot + theme_void()
gplot
install.packages("mapproj")
library(ggmap)
library(maps)
library(maptools)
library(ggplot2)
library(mapproj)
heat_data<- read.csv(file = "Data/StateDataforMap_2018-19week8.csv")
# x1
heat_data$Val<- gsub("[^0-9\\.]","", heat_data$ACTIVITY.LEVEL)
heat_val<-as.integer(heat_data$Val)
us <- map_data("state")
gplot <-ggplot()
gplot <- gplot + geom_map(data=us, map=us,aes(x=long, y=lat, map_id=region),fill="#ffffff", color="#ffffff", size=0.5)
gplot <- gplot + geom_map(data=heat_data, map=us, aes(fill=heat_val, map_id=tolower(STATENAME)),color="#000000", size=0.5)
gplot <- gplot + scale_fill_continuous(low='white',high='red', guide='colorbar')
# gplot = gplot + scale_fill_gradient2(low="darkgreen", mid="yellow", high="darkred", midpoint=5, limits=range(heat$level))
gplot <- gplot + ggtitle("2018-19 Influenza Season Week 8 ending Feb 23, 2019")
gplot <- gplot + coord_map("mercator")
gplot <- gplot + theme_void()
gplot
# Plot 1
{
library(ggplot2)
flu_data<-read.csv("FluView_StackedColumnChart_Data.csv")
flu_data<-transform(flu_data,weekcount=interaction(flu_data$YEAR,formatC(flu_data$WEEK, width=2, flag = "0"), sep=''))
flu_data$weekcount<-as.numeric(as.character(flu_data$weekcount))
flu_data$ID <- seq.int(nrow(flu_data))
sub<-flu_data[,c('A..Subtyping.not.Performed.','A..2009.H1N1.','A..H3.','H3N2v','B','BVic','BYam','ID')]
# sub
require(reshape2)
plot_data <- melt(sub, id.var='ID')
ggplot(plot_data, aes(x = ID, y = value,fill=variable)) +
geom_bar(stat = "identity")+
scale_x_discrete(limit = flu_data$ID,
labels = flu_data$weekcount)+
theme(axis.text.x = element_text(angle = 55, hjust = 1))+
xlab("Week")+
ylab("Number of positive specimen")+
ggtitle("Influenza positive tests reported to CDC by US Public Health Laboratories 2017-18 season")+
theme(plot.title = element_text(size=6))
}
getwd()
# Plot 1
{
library(ggplot2)
flu_data<-read.csv("part2\FluView_StackedColumnChart_Data.csv")
flu_data<-transform(flu_data,weekcount=interaction(flu_data$YEAR,formatC(flu_data$WEEK, width=2, flag = "0"), sep=''))
flu_data$weekcount<-as.numeric(as.character(flu_data$weekcount))
flu_data$ID <- seq.int(nrow(flu_data))
sub<-flu_data[,c('A..Subtyping.not.Performed.','A..2009.H1N1.','A..H3.','H3N2v','B','BVic','BYam','ID')]
# sub
require(reshape2)
plot_data <- melt(sub, id.var='ID')
ggplot(plot_data, aes(x = ID, y = value,fill=variable)) +
geom_bar(stat = "identity")+
scale_x_discrete(limit = flu_data$ID,
labels = flu_data$weekcount)+
theme(axis.text.x = element_text(angle = 55, hjust = 1))+
xlab("Week")+
ylab("Number of positive specimen")+
ggtitle("Influenza positive tests reported to CDC by US Public Health Laboratories 2017-18 season")+
theme(plot.title = element_text(size=6))
}
version
for(k in keywords){
if(is.null(stateTweetFullList)){
stateTweetFullList <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
} else {
uniqueCSV <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
stateTweetFullList <- rbind(stateTweetFullList, uniqueCSV)
}
}
library(twitteR)
library(keyring)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(ggmap)
library(ggplot2)
library(maptools)
library(maps)
library(usmap)
# Twitter API registration
setup_twitter_oauth(
key_get("twitter_consumer_key", keyring = "mykeyring"),
key_get("twitter_consumer_secret", keyring = "mykeyring"),
key_get("twitter_access_token", keyring = "mykeyring"),
key_get("twitter_access_secret", keyring = "mykeyring")
)
# Google API registration
register_google(key_get("GoogleAPI", keyring = "mykeyring"))
stateTweetFullList <- NULL
for(k in keywords){
if(is.null(stateTweetFullList)){
stateTweetFullList <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
} else {
uniqueCSV <- select(read.csv(glue('geo-unique-tweets-',{k},'.csv')), -c("X"))
stateTweetFullList <- rbind(stateTweetFullList, uniqueCSV)
}
}
stateTweetUniqueList <- unique(stateTweetFullList, by = "tweetID")
totalTweetsPerState <- count(stateTweetFullList, state)
plot_usmap(regions = "states", data = totalTweetsPerState, values = "n", lines = "black")+
scale_fill_continuous(low = "white", high = "red", name = "Flu Tweets", label = scales::comma)+
theme(legend.position = "right")
plot_usmap(regions = "states", data = totalTweetsPerState, values = "n", lines = "black")+
scale_fill_continuous(low = "white", high = "red", name = "Keyword Tweets", label = scales::comma)+
theme(plot.title = "Flu-related Keyword Tweets per State", legend.position = "right")
plot_usmap(regions = "states", data = totalTweetsPerState, values = "n", lines = "black")+
labs(title ="Flu-related Keyword Tweets per State")
plot_usmap(regions = "states", data = totalTweetsPerState, values = "n", lines = "black")+
labs(title ="Flu-related Keyword Tweets per State")+
scale_fill_continuous(low = "white", high = "red", name = "Keyword Tweets", label = scales::comma)+
theme(legend.position = "right")
shiny::runApp('shinyapp')
runApp('shinyapp')
